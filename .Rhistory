# Print the best parameters and model details
print(nn_model)
# Make predictions on the test set
predictions <- predict(nn_model, newdata = test_data)
# Evaluate model performance
confusion_matrix <- confusionMatrix(predictions, test_data$diabetes)
print(confusion_matrix)
nn_model <- train(
target ~ .,                  # Formula (predict diabetes using all other variables)
data = df_train,             # Training data
method = "nnet",               # Neural Network model
tuneLength = 5,                # Automatically tune parameters like size and decay
trControl = trainControl(      # Define training control
method = "cv",               # Use cross-validation
number = 5                   # Number of folds
),
trace = FALSE                  # Suppress training output for clarity
)
str(train)
str(df_test)
str(df_train)
# Make predictions on the test set
predictions <- predict(nn_model, newdata = df_train)
nn_model <- train(
target ~ .,                  # Formula (predict diabetes using all other variables)
data = df_train,             # Training data
method = "nnet",               # Neural Network model
tuneLength = 5,                # Automatically tune parameters like size and decay
trControl = trainControl(      # Define training control
method = "cv",               # Use cross-validation
number = 5                   # Number of folds
),
trace = FALSE                  # Suppress training output for clarity
)
str(train_data)
# Correct variables' types
#Could have used this df %>% mutate_if(is.character, as.factor)
df <- df %>%
mutate(target = as.factor(target),
pregnant = as.numeric(pregnant),
glucose  = as.numeric(glucose ),
pressure = as.numeric(pressure),
triceps  = as.numeric(triceps ),
insulin = as.numeric(insulin),
mass   = as.numeric(mass),
pedigree = as.numeric(pedigree),
age      = as.numeric(age)
)
# Handle missing values
#df$Age[is.na(df$Age)] = mean(df$Age, na.rm = TRUE)
#df = drop_na(df)
#sum(is.na(df)) --> No NA's
splitIndex <- createDataPartition(df$target, p = .70,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
#Decision Tree
model1 <- train(target~., data=df_train,
method = "rpart2"
)
pred <- predict(model1, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = 'pos')
cm$overall[1]
#Accuracy = 0.6478261
#Random Forest
model2 <- train(target~., data=df_train,
method = "rf",
ntree = 1000)
pred <- predict(model2, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
#Accuracy =
#Comparing the Variable Importances
varImp(model1)
plot(varImp(model1))
varImp(model2)
plot(varImp(model2))
#General Linearized Model ('glmnet') with Caret
model <- train(target~., data=df_train,
method = "glmnet"
)
pred <- predict(model, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target)
cm$overall[1]
#Accuracy = 0.6521739
varImp(model)
plot(varImp(model))
# Train a KNN model
set.seed(123) # For reproducibility
train_index <- createDataPartition(PimaIndiansDiabetes$diabetes, p = 0.8, list = FALSE)
train_data <- PimaIndiansDiabetes[train_index, ]
test_data <- PimaIndiansDiabetes[-train_index, ]
# Train a KNN model
knn_model <- train(
target ~ .,                  # Formula (predict diabetes using all other variables)
data = df_train,             # Training data
method = "knn",                # Specify KNN method
tuneLength = 10,               # Automatically tune the number of neighbors (k)
trControl = trainControl(      # Define training control
method = "cv",               # Use cross-validation
number = 5                   # Number of folds
)
)
# Print the best K value and model details
print(knn_model)
# Make predictions on the test set
predictions <- predict(knn_model, newdata = test_data)
# Evaluate model performance
confusion_matrix <- confusionMatrix(predictions, test_data$target)
# Train a KNN model
set.seed(123) # For reproducibility
train_index <- createDataPartition(PimaIndiansDiabetes$diabetes, p = 0.8, list = FALSE)
train_data <- PimaIndiansDiabetes[train_index, ]
test_data <- PimaIndiansDiabetes[-train_index, ]
# Train a KNN model
knn_model <- train(
target ~ .,                  # Formula (predict diabetes using all other variables)
data = df_train,             # Training data
method = "knn",                # Specify KNN method
tuneLength = 10,               # Automatically tune the number of neighbors (k)
trControl = trainControl(      # Define training control
method = "cv",               # Use cross-validation
number = 5                   # Number of folds
)
)
# Print the best K value and model details
print(knn_model)
# Make predictions on the test set
predictions <- predict(knn_model, newdata = df_test)
# Evaluate model performance
confusion_matrix <- confusionMatrix(predictions, df_test$target)
print(confusion_matrix)
#Accuracy: 0.6478261
library(mlbench)
library(caret)
library(tidyverse)
data(PimaIndiansDiabetes)
df <- tibble(PimaIndiansDiabetes)
#Cleaning Data
# Remove some columns (Don't need to perform for this dataset)
#df <- df %>% select(-PassengerId, -Ticket, -Name, -Cabin)
# Set the target variable
df <- df %>% rename(target=diabetes)
# Correct variables' types
#Could have used this df %>% mutate_if(is.character, as.factor)
df <- df %>%
mutate(target = as.factor(target),
pregnant = as.numeric(pregnant),
glucose  = as.numeric(glucose ),
pressure = as.numeric(pressure),
triceps  = as.numeric(triceps ),
insulin = as.numeric(insulin),
mass   = as.numeric(mass),
pedigree = as.numeric(pedigree),
age      = as.numeric(age)
)
# Handle missing values
#df$Age[is.na(df$Age)] = mean(df$Age, na.rm = TRUE)
#df = drop_na(df)
#sum(is.na(df)) --> No NA's
splitIndex <- createDataPartition(df$target, p = .70,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
# Train a KNN model
knn_model <- train(
target ~ .,                  # Formula (predict diabetes using all other variables)
data = df_train,             # Training data
method = "knn",                # Specify KNN method
tuneLength = 10,               # Automatically tune the number of neighbors (k)
trControl = trainControl(      # Define training control
method = "cv",               # Use cross-validation
number = 5                   # Number of folds
)
)
# Print the best K value and model details
print(knn_model)
# Make predictions on the test set
predictions <- predict(knn_model, newdata = df_test)
# Evaluate model performance
confusion_matrix <- confusionMatrix(predictions, df_test$target)
print(confusion_matrix)
#Accuracy: 0.6478261
#Models: knn, nnet
#KNN
library(class)
# Train a KNN model
knn_model <- train(
target ~ .,
data = df_train,
method = "knn",
tuneLength = 10,               # Automatically tune the number of neighbors (k)
trControl = trainControl(      # Define training control
method = "cv",               # Use cross-validation
number = 5                   # Number of folds
)
)
# Print the best K value and model details
print(knn_model)
# Make predictions on the test set
predictions <- predict(knn_model, newdata = df_test)
# Evaluate model performance
confusion_matrix <- confusionMatrix(predictions, df_test$target)
print(confusion_matrix)
#Accuracy = 0.6435
#########################
#nnet --> Neural Network
#install.packages(c('neuralnet','keras','tensorflow'),dependencies = T)
library(mlbench)
library(nnet)
# Neural Network model
nn_model <- train(
target~., data = df_train,
method = "nnet", tuneLength = 5,
trControl = trainControl(
method = "cv",
number = 5
),
trace = FALSE
)
pred <- predict(nn_model, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target)
cm$overall[1]
#Accuracy = 0.6521739
plot(model,rep = "best")
#nnet --> Neural Network
#install.packages(c('neuralnet','keras','tensorflow'),dependencies = T)
library(mlbench)
library(nnet)
# Neural Network model
nn_model <- train(
target~., data = df_train,
method = "nnet", tuneLength = 5,
trControl = trainControl(
method = "cv",
number = 5
),
trace = FALSE
)
pred <- predict(nn_model, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target)
cm$overall[1]
#Accuracy = 0.6521739
plot(model,rep = "best")
#Accuracy = 0.6521739
```
#nnet --> Neural Network
#install.packages(c('neuralnet','keras','tensorflow'),dependencies = T)
library(mlbench)
library(nnet)
# Neural Network model
nn_model <- train(
target~., data = df_train,
method = "nnet", tuneLength = 5,
trControl = trainControl(
method = "cv",
number = 5
),
trace = FALSE
)
pred <- predict(nn_model, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target)
cm$overall[1]
#Accuracy = 0.6521739
knitr::opts_chunk$set(message = FALSE)
#Retrive Data
library(mlbench)
library(caret)
library(tidyverse)
data(PimaIndiansDiabetes)
df <- tibble(PimaIndiansDiabetes)
df
str(df)
#Retrive Data
library(mlbench)
library(caret)
library(tidyverse)
data(PimaIndiansDiabetes)
df <- tibble(PimaIndiansDiabetes)
#Clean Data
#Cleaning Data
# Remove some columns (Don't need to perform for this dataset)
#df <- df %>% select(-PassengerId, -Ticket, -Name, -Cabin)
# Set the target variable
df <- df %>% rename(target=diabetes)
# Correct variables' types
#Could have used this df %>% mutate_if(is.character, as.factor)
df <- df %>%
mutate(target = as.factor(target),
pregnant = as.numeric(pregnant),
glucose  = as.numeric(glucose ),
pressure = as.numeric(pressure),
triceps  = as.numeric(triceps ),
insulin = as.numeric(insulin),
mass   = as.numeric(mass),
pedigree = as.numeric(pedigree),
age      = as.numeric(age)
)
# Handle missing values
#df$Age[is.na(df$Age)] = mean(df$Age, na.rm = TRUE)
#df = drop_na(df)
#sum(is.na(df)) --> No NA's
splitIndex <- createDataPartition(df$target, p = .70,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
# Handle missing values
#df$Age[is.na(df$Age)] = mean(df$Age, na.rm = TRUE)
#df = drop_na(df)
#sum(is.na(df)) --> No NA's
splitIndex <- createDataPartition(df$target, p = .85,
list = FALSE)
df_train <- df[ splitIndex,]
df_test <- df[-splitIndex,]
getModelInfo('ranger')$ranger$parameters
# Tell caret to do Approach 2, i.e. Cross-Validation
trControl = trainControl(method = "cv",
number = 7)
# Do Approach 2
tree_approach2 <- train(target~., data=df_train,
method = "rpart2",
trControl = trControl
)
plot(tree_approach2)
# Tell caret to do Approach 2, i.e. Cross-Validation
trControl = trainControl(method = "cv",
number = 7)
# Do Approach 2
tree_approach2 <- train(target~., data=df_train,
method = "rpart2",
trControl = trControl
)
plot(tree_approach2)
# Tell caret to do Approach 2, i.e. Cross-Validation
trControl = trainControl(method = "cv",
number = 7)
# Do Approach 2
tree_approach2 <- train(target~., data=df_train,
method = "ranger",
trControl = trControl
)
# Do Approach 2
tree_approach2 <- train(target~., data=df_train,
method = "ranger",
trControl = trControl
)
plot(tree_approach2)
#Cross Validation of with a max tree depth of 2 has the highest Accuracy
```
print(tree_approach2)
pred <- predict(tree_approach2, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "1")
str(df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
# Tell caret to do Approach 2, i.e. Cross-Validation
trControl = trainControl(method = "cv",
number = 2)
# Do Approach 2
tree_approach2 <- train(target~., data=df_train,
method = "ranger",
trControl = trControl
)
# Do Approach 2
tree_approach2 <- train(target~., data=df_train,
method = "ranger",
trControl = trControl
)
plot(tree_approach2)
plot(tree_approach2)
print(tree_approach2)
pred <- predict(tree_approach2, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
plot(tree_approach2)
print(tree_approach2)
pred <- predict(tree_approach2, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
# Tell caret to do Approach 2, i.e. Cross-Validation
trControl = trainControl(method = "cv",
number = 7)
# Do Approach 2
tree_approach2 <- train(target~., data=df_train,
method = "ranger",
trControl = trControl
)
plot(tree_approach2)
print(tree_approach2)
pred <- predict(tree_approach2, df_test)
cm <- confusionMatrix(data = pred, reference = df_test$target, positive = "pos")
cm$overall[1]
#Cross Validation of 7 with a max tree depth of 2 has the highest Accuracy
#Accuracy = 0.7652174
cm$overall[1]
plot(tree_approach2)
print(tree_approach2)
# Train a KNN model
knn_model <- train(
target ~ .,
data = df_train,
method = "knn",
tuneLength = 10,
trControl = trainControl(
method = "cv",
number = 7
)
)
# Make predictions on the test set
predictions <- predict(knn_model, newdata = df_test)
# Evaluate model performance
confusion_matrix <- confusionMatrix(predictions, df_test$target)
print(confusion_matrix)
# Evaluate model performance
confusion_matrix <- confusionMatrix(predictions, df_test$target)
print(confusion_matrix)
# Train a Bagging model
bag_model <- bagging(
target ~ .,                  # Formula (predict diabetes using all other variables)
data = df_train,             # Training data
coob = TRUE                    # Use out-of-bag error for evaluation
)
# Train a Bagging model
bag_model <- bagging(
target ~ .,                  # Formula (predict diabetes using all other variables)
data = df_train,             # Training data
coob = TRUE                    # Use out-of-bag error for evaluation
)
# Train a Bagging model
library(ipred)
bag <- bagging(
formula = target~., # formula
data = df_train, # data set
nbagg = 150,   # number of bagging trees to created
coob = TRUE # whether oob is calculated
)
#display fitted bagged model
bag
# Print model summary
print(bag_model)
bag_model <- bagging(
formula = target~., # formula
data = df_train, # data set
nbagg = 150,   # number of bagging trees to created
coob = TRUE # whether oob is calculated
)
#display fitted bagged model
bag
# Print model summary
print(bag_model)
# Make predictions on the test set
predictions <- predict(bag_model, newdata = df_test)
# Evaluate model performance
confusion_matrix <- confusionMatrix(predictions, df_test$target)
print(confusion_matrix)
bag_model <- bagging(
formula = target~., # formula
data = df_train, # data set
nbagg = 150,   # number of bagging trees to created
coob = TRUE,   # whether oob is calculated
cv= 7)
bag_model <- bagging(
formula = target~., # formula
data = df_train, # data set
nbagg = 150,   # number of bagging trees to created
coob = TRUE,   # whether oob is calculated
cv= 7)
bag_model <- bagging(
formula = target~., # formula
data = df_train, # data set
nbagg = 150,   # number of bagging trees to created
coob = TRUE,   # whether oob is calculated
cv= 7)
# Print model summary
print(bag_model)
# Make predictions on the test set
predictions <- predict(bag_model, newdata = df_test)
# Evaluate model performance
confusion_matrix <- confusionMatrix(predictions, df_test$target)
print(confusion_matrix)
library(caret)
cv_settings <- trainControl(method = "cv", number = 7, savePredictions = "final")
cv_settings <- trainControl(method = "cv", number = 7, savePredictions = "final")
logistic_model_cv <- train(target~. ,
data = df_train,
method = "glm",
family = binomial(),
trControl = cv_settings)
logistic_model_cv$results
logistic_model_cv$results
library(caret)
cv_settings <- trainControl(method = "cv", number = 7, savePredictions = "final")
logistic_model_cv <- train(target~. ,
data = df_train,
method = "glm",
family = binomial(),
trControl = cv_settings)
# Print model summary
print(logistic_model_cv)
# Make predictions on the test set
predictions <- predict(logistic_model_cv, newdata = df_test)
# Evaluate model performance
confusion_matrix <- confusionMatrix(predictions, df_test$target)
print(confusion_matrix)
getcw()
cwd()
cwd
getwd()
setwd("C:/Users/student/OneDrive - Bryant University/Fall 2024/math_421_fall24/MATH421")
getwd()
library(rmarkdown)
output_file <- render("assignment10.Rmd")
